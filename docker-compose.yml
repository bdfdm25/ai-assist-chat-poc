version: "3.8"

services:
  # Backend API Service
  api:
    build:
      context: ./assist-chat-api
      dockerfile: Dockerfile
    container_name: assist-chat-api
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - API_PORT=3000
      - APP=http://localhost:4200
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4-turbo-preview}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-1000}
      - OPENAI_TEMPERATURE=${OPENAI_TEMPERATURE:-0.7}
      - THROTTLE_TTL=${THROTTLE_TTL:-60}
      - THROTTLE_LIMIT=${THROTTLE_LIMIT:-10}
      - CIRCUIT_BREAKER_FAILURE_THRESHOLD=${CIRCUIT_BREAKER_FAILURE_THRESHOLD:-5}
      - CIRCUIT_BREAKER_SUCCESS_THRESHOLD=${CIRCUIT_BREAKER_SUCCESS_THRESHOLD:-2}
      - CIRCUIT_BREAKER_TIMEOUT=${CIRCUIT_BREAKER_TIMEOUT:-60000}
    networks:
      - assist-chat-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend Application Service
  app:
    build:
      context: ./assist-chat-app
      dockerfile: Dockerfile
    container_name: assist-chat-app
    restart: unless-stopped
    ports:
      - "4200:80"
    depends_on:
      api:
        condition: service_healthy
    networks:
      - assist-chat-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  assist-chat-network:
    driver: bridge
